{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import numpy as np \n",
    "#import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Free  hour  minu  weekday\n",
      "0     0     0     0        0\n",
      "1     0     0    15        0\n",
      "2     0     0    30        0\n",
      "3     0     0    45        0\n",
      "4     0     1     0        0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"final_data.csv\",parse_dates=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['Free','hour','minu','weekday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_name='Free'):\n",
    "    \"\"\"Parses the csv file in TRAIN_URL and TEST_URL.\"\"\"\n",
    "    train_path=\"train_data.csv\"\n",
    "    \n",
    "    #train_path=\"final_data.csv\"\n",
    "    # Parse the local CSV file.\n",
    "    train = pd.read_csv(filepath_or_buffer=train_path,\n",
    "                        names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                        header=0,  # ignore the first row of the CSV file.\n",
    "                        skipinitialspace=True,\n",
    "                        #skiprows=1\n",
    "                       )\n",
    "    \n",
    "    #df5['Free'].apply(str)\n",
    "    #train.Free = train.Free.astype(str)\n",
    "    train.hour = train.hour.astype(str)\n",
    "    train.minu= train.minu.astype(str)\n",
    "    train.weekday= train.weekday.astype(str)\n",
    "    \n",
    "\n",
    "    # train now holds a pandas DataFrame, which is data structure\n",
    "    # analogous to a table.\n",
    "    \n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "    train_features, train_label = train, train.pop(label_name)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply the preceding logic to the test set.\n",
    "    test_path = \"test_data.csv\"\n",
    "    \n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0,  # ignore the first row of the CSV file.\n",
    "                        skipinitialspace=True,\n",
    "                        skiprows=1)\n",
    "\n",
    "    \n",
    "    #test.Free = test.Free.astype(str)\n",
    "    test.hour = test.hour.astype(str)\n",
    "    test.minu= test.minu.astype(str)\n",
    "    test.weekday= test.weekday.astype(str)\n",
    "    \n",
    "    print(test.dtypes)\n",
    "    test_features, test_label = test, test.pop(label_name)    \n",
    "    #print(test.hour)\n",
    "    # Return four DataFrames.\n",
    "    return (train_features, train_label), (test_features, test_label)\"\"\"\n",
    "    return (train_features, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call load_data() to parse the CSV file.\n",
    "#(train_feature, train_label), (test_feature, test_label) = load_data()\n",
    "\n",
    "(train_feature, train_label) = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hour minu weekday\n",
      "0    0    0       0\n",
      "1    0   15       0\n",
      "2    0   30       0\n",
      "3    0   45       0\n",
      "4    1    0       0\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Free, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_feature.head())\n",
    "print(train_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'weekday', ['0', '1', '2', '3', '4','5','6'])\n",
    "hour = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'hour', [ '0', '1', '2', '3', '4','5','6','7','8','10','12','13','14','15','16','17','18','19','20','21','22','23'])\n",
    "minu = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'minu', [ '0', '15', '30', '45'])\n",
    "\n",
    "base_columns = [\n",
    "    tf.feature_column.indicator_column(weekday),\n",
    "    tf.feature_column.indicator_column(hour),\n",
    "    tf.feature_column.indicator_column(minu)\n",
    "]\n",
    "\n",
    "\n",
    "weekday_x_hour_x_minu = tf.feature_column.crossed_column(\n",
    "    ['weekday', 'hour','minu'], hash_bucket_size=1000)\n",
    "\n",
    "weekday_x_hour = tf.feature_column.crossed_column(\n",
    "    ['weekday', 'hour'], hash_bucket_size=1000)\n",
    "\n",
    "hour_x_minu = tf.feature_column.crossed_column(\n",
    "    ['hour','minu'], hash_bucket_size=1000)\n",
    "\n",
    "crossed_columns = [\n",
    "     tf.feature_column.indicator_column(weekday_x_hour_x_minu),\n",
    "     tf.feature_column.indicator_column(weekday_x_hour) , \n",
    "     tf.feature_column.indicator_column(hour_x_minu)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Koushik\\AppData\\Local\\Temp\\tmp0l_2s9de\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002734FB12390>, '_is_chief': True, '_task_type': 'worker', '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_master': '', '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_session_config': None, '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Koushik\\\\AppData\\\\Local\\\\Temp\\\\tmp0l_2s9de', '_task_id': 0}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=base_columns+crossed_columns,hidden_units=[6, 4,2],n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Koushik\\AppData\\Local\\Temp\\tmp0l_2s9de\\model.ckpt.\n",
      "INFO:tensorflow:loss = 34.62224, step = 1\n",
      "INFO:tensorflow:global_step/sec: 39.1549\n",
      "INFO:tensorflow:loss = 3.2257025, step = 101 (2.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5495\n",
      "INFO:tensorflow:loss = 4.7298217, step = 201 (2.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4975\n",
      "INFO:tensorflow:loss = 3.974878, step = 301 (2.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2111\n",
      "INFO:tensorflow:loss = 5.2783957, step = 401 (2.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0241\n",
      "INFO:tensorflow:loss = 6.6478357, step = 501 (2.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7849\n",
      "INFO:tensorflow:loss = 5.4931087, step = 601 (2.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.68\n",
      "INFO:tensorflow:loss = 6.126913, step = 701 (2.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2277\n",
      "INFO:tensorflow:loss = 6.3231573, step = 801 (1.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0467\n",
      "INFO:tensorflow:loss = 4.7516103, step = 901 (1.726 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Koushik\\AppData\\Local\\Temp\\tmp0l_2s9de\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.1996315.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x2734fb12780>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "        \n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat(count=None).batch(batch_size)\n",
    "        \n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "classifier.train(\n",
    "        input_fn=lambda:train_input_fn(train_feature, train_label, 50 ),\n",
    "        steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels=None, batch_size=None):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert inputs to a tf.dataset object.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "   Free  hour  minu  weekday\n",
      "0     0     0    15        3\n",
      "1     0     0    30        3\n",
      "2     0     0    45        3\n",
      "3     0     1     0        3\n",
      "4     0     1    15        3\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"topredict.csv\",parse_dates=True)\n",
    "\n",
    "predict_x= {  'hour':[ ],\n",
    "        'minu':[ ] ,\n",
    "        'weekday':[ ]\n",
    "}\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "\"\"\"\n",
    "predict_x = {\n",
    "        'hour':['12','18','3'],\n",
    "        'minu':['15','15','45'] ,\n",
    "        'weekday':['3','3','0']\n",
    "\n",
    "    }\n",
    "\"\"\"\n",
    "predict_x['hour'] = df.hour.astype(str)\n",
    "predict_x['minu']= df.minu.astype(str)\n",
    "predict_x['weekday']= df.weekday.astype(str)\n",
    "df['Free'] = [0 for x in range(df.shape[0])]\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Estimator.predict at 0x0000027390B9EBF8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Koushik\\AppData\\Local\\Temp\\tmp0l_2s9de\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(predict_x,\n",
    "                                  labels=None,\n",
    "                                  batch_size=50))\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "i=0\n",
    "for pred_dict in zip(predictions):\n",
    "    if pred_dict[0]['classes'] == [b'1']:\n",
    "        \n",
    "        df.iloc[i,0]=1\n",
    "        \n",
    "    i=i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predictedValue.csv\",mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(label_name='Free'):\n",
    "    \"\"\"Parses the csv file in TRAIN_URL and TEST_URL.\"\"\"\n",
    "    #train_path=\"train_data.csv\"\n",
    "    \"\"\"\n",
    "    train_path=\"final_data.csv\"\n",
    "    # Parse the local CSV file.\n",
    "    train = pd.read_csv(filepath_or_buffer=train_path,\n",
    "                        names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                        header=0,  # ignore the first row of the CSV file.\n",
    "                        skipinitialspace=True,\n",
    "                        #skiprows=1\n",
    "                       )\n",
    "    \n",
    "    #df5['Free'].apply(str)\n",
    "    #train.Free = train.Free.astype(str)\n",
    "    train.hour = train.hour.astype(str)\n",
    "    train.minu= train.minu.astype(str)\n",
    "    train.weekday= train.weekday.astype(str)\n",
    "    \n",
    "\n",
    "    # train now holds a pandas DataFrame, which is data structure\n",
    "    # analogous to a table.\n",
    "    \n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "    train_features, train_label = train, train.pop(label_name)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply the preceding logic to the test set.\n",
    "    test_path = \"test_data.csv\"\n",
    "    \n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0,  # ignore the first row of the CSV file.\n",
    "                        skipinitialspace=True,\n",
    "                        skiprows=1)\n",
    "\n",
    "    \n",
    "    #test.Free = test.Free.astype(str)\n",
    "    test.hour = test.hour.astype(str)\n",
    "    test.minu= test.minu.astype(str)\n",
    "    test.weekday= test.weekday.astype(str)\n",
    "    \n",
    "    print(test.dtypes)\n",
    "    test_features, test_label = test, test.pop(label_name)    \n",
    "    #print(test.hour)\n",
    "    # Return four DataFrames.\n",
    "    return (test_features, test_label)\n",
    "    #return (train_features, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free        int64\n",
      "hour       object\n",
      "minu       object\n",
      "weekday    object\n",
      "dtype: object\n",
      "  hour minu weekday\n",
      "0    0   30       3\n",
      "1    0   45       3\n",
      "2    1    0       3\n",
      "3    1   15       3\n",
      "4    1   30       3\n"
     ]
    }
   ],
   "source": [
    "(test_feature, test_label) = load_test_data()\n",
    "\n",
    "print(test_feature.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "   Free  hour  minu  weekday\n",
      "0     1     0    15        3\n",
      "1     1     0    30        3\n",
      "2     1     0    45        3\n",
      "3     1     1     0        3\n",
      "4     1     1    15        3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(\"test_data.csv\",parse_dates=True)\n",
    "\n",
    "test_feature= {  'hour':[ ],\n",
    "        'minu':[ ] ,\n",
    "        'weekday':[ ]\n",
    "}\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "\"\"\"\n",
    "predict_x = {\n",
    "        'hour':['12','18','3'],\n",
    "        'minu':['15','15','45'] ,\n",
    "        'weekday':['3','3','0']\n",
    "\n",
    "    }\n",
    "    \n",
    "\"\"\"\n",
    "test_label=[]\n",
    "test_feature['hour'] = df.hour.astype(str)\n",
    "test_feature['minu']= df.minu.astype(str)\n",
    "test_feature['weekday']= df.weekday.astype(str)\n",
    "test_label=df.weekday.astype(int)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hour': 0       0\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "5       1\n",
      "6       1\n",
      "7       2\n",
      "8       2\n",
      "9       2\n",
      "10      2\n",
      "11      3\n",
      "12      3\n",
      "13      3\n",
      "14      3\n",
      "15      4\n",
      "16      4\n",
      "17      4\n",
      "18      4\n",
      "19      5\n",
      "20      5\n",
      "21      5\n",
      "22      5\n",
      "23      6\n",
      "24      6\n",
      "25      6\n",
      "26      6\n",
      "27      7\n",
      "28      7\n",
      "29      7\n",
      "       ..\n",
      "642    16\n",
      "643    17\n",
      "644    17\n",
      "645    17\n",
      "646    17\n",
      "647    18\n",
      "648    18\n",
      "649    18\n",
      "650    18\n",
      "651    19\n",
      "652    19\n",
      "653    19\n",
      "654    19\n",
      "655    20\n",
      "656    20\n",
      "657    20\n",
      "658    20\n",
      "659    21\n",
      "660    21\n",
      "661    21\n",
      "662    21\n",
      "663    22\n",
      "664    22\n",
      "665    22\n",
      "666    22\n",
      "667    23\n",
      "668    23\n",
      "669    23\n",
      "670    23\n",
      "671     0\n",
      "Name: hour, Length: 672, dtype: object, 'weekday': 0      3\n",
      "1      3\n",
      "2      3\n",
      "3      3\n",
      "4      3\n",
      "5      3\n",
      "6      3\n",
      "7      3\n",
      "8      3\n",
      "9      3\n",
      "10     3\n",
      "11     3\n",
      "12     3\n",
      "13     3\n",
      "14     3\n",
      "15     3\n",
      "16     3\n",
      "17     3\n",
      "18     3\n",
      "19     3\n",
      "20     3\n",
      "21     3\n",
      "22     3\n",
      "23     3\n",
      "24     3\n",
      "25     3\n",
      "26     3\n",
      "27     3\n",
      "28     3\n",
      "29     3\n",
      "      ..\n",
      "642    2\n",
      "643    2\n",
      "644    2\n",
      "645    2\n",
      "646    2\n",
      "647    2\n",
      "648    2\n",
      "649    2\n",
      "650    2\n",
      "651    2\n",
      "652    2\n",
      "653    2\n",
      "654    2\n",
      "655    2\n",
      "656    2\n",
      "657    2\n",
      "658    2\n",
      "659    2\n",
      "660    2\n",
      "661    2\n",
      "662    2\n",
      "663    2\n",
      "664    2\n",
      "665    2\n",
      "666    2\n",
      "667    2\n",
      "668    2\n",
      "669    2\n",
      "670    2\n",
      "671    3\n",
      "Name: weekday, Length: 672, dtype: object, 'minu': 0      15\n",
      "1      30\n",
      "2      45\n",
      "3       0\n",
      "4      15\n",
      "5      30\n",
      "6      45\n",
      "7       0\n",
      "8      15\n",
      "9      30\n",
      "10     45\n",
      "11      0\n",
      "12     15\n",
      "13     30\n",
      "14     45\n",
      "15      0\n",
      "16     15\n",
      "17     30\n",
      "18     45\n",
      "19      0\n",
      "20     15\n",
      "21     30\n",
      "22     45\n",
      "23      0\n",
      "24     15\n",
      "25     30\n",
      "26     45\n",
      "27      0\n",
      "28     15\n",
      "29     30\n",
      "       ..\n",
      "642    45\n",
      "643     0\n",
      "644    15\n",
      "645    30\n",
      "646    45\n",
      "647     0\n",
      "648    15\n",
      "649    30\n",
      "650    45\n",
      "651     0\n",
      "652    15\n",
      "653    30\n",
      "654    45\n",
      "655     0\n",
      "656    15\n",
      "657    30\n",
      "658    45\n",
      "659     0\n",
      "660    15\n",
      "661    30\n",
      "662    45\n",
      "663     0\n",
      "664    15\n",
      "665    30\n",
      "666    45\n",
      "667     0\n",
      "668    15\n",
      "669    30\n",
      "670    45\n",
      "671     0\n",
      "Name: minu, Length: 672, dtype: object}\n"
     ]
    }
   ],
   "source": [
    "print(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Estimator.predict at 0x000002734FE0F410>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Koushik\\AppData\\Local\\Temp\\tmp0l_2s9de\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(test_feature,\n",
    "                                  labels=None,\n",
    "                                  batch_size=50))\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "i=0\n",
    "pred_label=[]\n",
    "for pred_dict in zip(predictions):\n",
    "    if pred_dict[0]['classes'] == [b'1']:\n",
    "        \n",
    "        pred_label.append(1)\n",
    "        \n",
    "    else:\n",
    "        pred_label.append(0)\n",
    "    i=i+1\n",
    "\n",
    "#print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_compare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-cb58772ef0bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Compute confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_compare\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion matrix, without normalization'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_compare' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_compare, pred_label)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, diagnosis)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, diagnosis, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
